{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db2f3d79-d244-43b1-9018-aee97369fc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amil\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\amil\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "c:\\Users\\amil\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import nbimporter\n",
    "import torch \n",
    "sys.path.append(os.path.abspath(\"C:/Users/amil/OneDrive/Documents/AI-Driven Personalized Therapy Recommendations system/Module_3/Predictive_model/scripts\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f53fceeb-e563-4c55-a339-dccc217d3e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amil\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All models loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from utils.model_loader import sentiment_tokenizer, sentiment_model, predective_model,predective_model_tokenizer\n",
    "from utils.intent_recognition import intent_recognition, INTENT_CATEGORIES\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2737e0d2-3500-4a2d-8292-fe2ae329021b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è API request failed (Attempt 1/6): 404 Client Error: Not Found for url: https://openrouter.ai/api/v1/chat/completions\n",
      "‚ö†Ô∏è API request failed (Attempt 2/6): 404 Client Error: Not Found for url: https://openrouter.ai/api/v1/chat/completions\n",
      "‚ö†Ô∏è API request failed (Attempt 3/6): 404 Client Error: Not Found for url: https://openrouter.ai/api/v1/chat/completions\n",
      "‚ö†Ô∏è API request failed (Attempt 4/6): 404 Client Error: Not Found for url: https://openrouter.ai/api/v1/chat/completions\n",
      "‚ö†Ô∏è API request failed (Attempt 5/6): 404 Client Error: Not Found for url: https://openrouter.ai/api/v1/chat/completions\n",
      "‚ö†Ô∏è API request failed (Attempt 6/6): 404 Client Error: Not Found for url: https://openrouter.ai/api/v1/chat/completions\n",
      "üõë Detected Intent: Error: Unable to determine intent.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Sentiment: Reassurance & Coping Strategies\n",
      "üîç Using predective_model_tokenizer from model_loader\n",
      "üß† Mental Health Prediction: Schizophrenia\n",
      "\n",
      "‚úÖ Final Result: {'intent': 'Error: Unable to determine intent.', 'sentiment': 'Reassurance & Coping Strategies', 'mental_health_prediction': 'Schizophrenia'}\n"
     ]
    }
   ],
   "source": [
    "# Mental health prediction and sentiment mapping\n",
    "mental_health_mapping = {\n",
    "    0: \"ADHD\",\n",
    "    1: \"Anxiety\",\n",
    "    2: \"BDD\",\n",
    "    3: \"Bipolar\",\n",
    "    4: \"BPD\",\n",
    "    5: \"Depression\",\n",
    "    6: \"Eating Disorder\",\n",
    "    7: \"Hoarding Disorder\",\n",
    "    8: \"Mental Illness\",\n",
    "    9: \"Normal\",\n",
    "    10: \"OCD\",\n",
    "    11: \"Off My Chest\",\n",
    "    12: \"Panic Disorder\",\n",
    "    13: \"Personality Disorder\",\n",
    "    14: \"PTSD\",\n",
    "    15: \"Schizophrenia\",\n",
    "    16: \"Social Anxiety\",\n",
    "    17: \"Stress\",\n",
    "    18: \"Suicidal\"\n",
    "}\n",
    "\n",
    "ai_response_mapping = {\n",
    "    0: \"De-escalation & Validation\",\n",
    "    1: \"Reframing & Encouragement\",\n",
    "    2: \"Reassurance & Coping Strategies\",\n",
    "    3: \"Encouragement & Positive Reinforcement\",\n",
    "    4: \"Active Listening & Encouragement\",\n",
    "    5: \"Compassion & Support\",\n",
    "    6: \"Clarification & Stability\"\n",
    "}\n",
    "\n",
    "def mental_health_pipeline(text):\n",
    "    # Step 1: Intent Recognition\n",
    "    intent = intent_recognition(text)\n",
    "    print(f\"üõë Detected Intent: {intent}\")\n",
    "\n",
    "    # Step 2: Sentiment Analysis\n",
    "    inputs = sentiment_tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = sentiment_model(**inputs)\n",
    "\n",
    "    sentiment_scores = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "    sentiment_idx = torch.argmax(sentiment_scores).item()\n",
    "    sentiment_label = ai_response_mapping.get(sentiment_idx, \"Unknown\")\n",
    "    print(f\"üìä Sentiment: {sentiment_label}\")\n",
    "\n",
    "    # Step 3: Mental Health Prediction\n",
    "    print(f\"üîç Using predective_model_tokenizer from model_loader\")\n",
    "\n",
    "    pred_inputs = predective_model_tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        add_special_tokens=True,\n",
    "        padding=True,\n",
    "        truncation=True\n",
    "    ).to(device)\n",
    "\n",
    "    # Remove token_type_ids if they exist\n",
    "    if \"token_type_ids\" in pred_inputs:\n",
    "        del pred_inputs[\"token_type_ids\"]\n",
    "\n",
    "    predective_model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = predective_model(**pred_inputs)\n",
    "\n",
    "    # ‚úÖ Extract the logits and map to labels\n",
    "    logits = outputs[\"logits\"]\n",
    "    prediction_idx = torch.argmax(logits).item()\n",
    "    prediction_label = mental_health_mapping.get(prediction_idx, \"Unknown\")\n",
    "\n",
    "    print(f\"üß† Mental Health Prediction: {prediction_label}\")\n",
    "    \n",
    "    return {\n",
    "        \"intent\": intent,\n",
    "        \"sentiment\": sentiment_label,\n",
    "        \"mental_health_prediction\": prediction_label\n",
    "    }\n",
    "\n",
    "text = \"\"\"You wake up to silence, but it feels heavy‚Äîlike the calm before a storm. As you sit up in bed, a voice murmurs your name. It sounds close, as if someone is right next to you, but you‚Äôre alone. You shake your head, willing it to go away, but the voice persists.\n",
    "\n",
    "\"You‚Äôre being watched.\"\n",
    "\n",
    "A chill runs down your spine. You scan the room. The window blinds look slightly out of place. Did someone move them? Were they here while you slept? Your heart pounds as paranoia takes root. You try to shake it off, telling yourself it‚Äôs just your mind playing tricks on you, but the doubt lingers.\n",
    "\n",
    "The morning news plays on your phone, but the words feel like they‚Äôre directed at you. The anchor's gaze seems too intense‚Äîdo they know something? Are they sending a message? You pause the video, unsettled.\n",
    "\n",
    "\"\"\"\n",
    "result = mental_health_pipeline(text)\n",
    "print(\"\\n‚úÖ Final Result:\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d692a1d-c7e1-4826-8ece-23bfa5757e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model type: <class 'utils.model_loader.CustomDebertaClassifier'>\n",
      "Tokenizer type: <class 'transformers.models.deberta_v2.tokenization_deberta_v2_fast.DebertaV2TokenizerFast'>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c364071-7505-4be7-a9d2-5bed27deedd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
